{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrapy\n",
    "- 파이썬 언어를 이용한 웹 데이터 수집 프레임워크\n",
    "    - 프레임워크와 라이브러리 또는 패키지의 차이\n",
    "    - 프레임워크는 특정 목적을 가진 기능의 코드가 미리 설정되어서 빈칸채우기 식으로 코드를 작성\n",
    "    - 패키지는 다른사람이 작성해 놓은 코드를 가져다가 사용하는 방법\n",
    "- scrapy\n",
    "    - pip install scrapy\n",
    "- tree\n",
    "    - sudo apt install tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Scrapy Project\n",
    "- scrapy project create\n",
    "     - `!scrapy startproject crawler` : crawler 폴더 생성\n",
    "- scrapy struct\n",
    "- gmarket 베스트 상품 링크 수집, 링크 안에 있는 상세 정보 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.http import TextResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: scrapy.cfg already exists in C:\\Code_dss15\\220_영상강의_실습\\06_scrapy\\crawler\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scrapy의 구조\n",
    "- 기본적으로 startproject로 만들어진 폴더안에 같은 이름이로 폴더 하나 더생김\n",
    "    - startproject crawler\n",
    "        - crawler/crawler 안의 이야기\n",
    "    - tutorial/    \n",
    "        - scrapy.cfg # deploy configuration file(구성 파일 배포)\n",
    "        - tutorial/ # project's Python module, you'll import your code from here\n",
    "            - `__init__.py`\n",
    "            - items.py # project items definition file\n",
    "            - middlewares.py # project middlewares file\n",
    "            - pipelines.py # project pipelines file\n",
    "            - settings.py # project settings file\n",
    "            - spiders/ # a directory where you'll later put your spiders\n",
    "                - `__init__.py`\n",
    "- crawler/crawler/spiders (폴더)\n",
    "    - 어떤 웹서비스를 어떻게 크롤링 할 것인지에 대한 코드 작성\n",
    "- crawler/crawler/items.py\n",
    "    - 모델에 해당하는 코드, 저장하는 데이터의 자료구조를 설정\n",
    "- crawler/crawler/piplines.py\n",
    "    - 스크래핑한 결과물을 item 형태로 구성하고 처리하는 방법에 대한 코드\n",
    "- crawler/crawler/settings.py\n",
    "    - 스크래핑 할때의 환경 설정값을 지정\n",
    "    - robots.txt: 따를지, 안따를지\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gmarket 베스트 셀러 상품 수집\n",
    "- 상품명, 상세페이지 URL, 원가, 판매가, 할인율\n",
    "- xpath 확인\n",
    "- items.py\n",
    "- spider.py\n",
    "- 크롤러 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://corners.gmarket.co.kr/Bestsellers'\n",
    "req = requests.get(url)\n",
    "resp = TextResponse(req.url, body=req.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = resp.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li')\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = resp.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li/div/a/@href').extract()\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3b42b43cf43c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextResponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"itemcase_basic\"]/h1/text()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ms_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"itemcase_basic\"]/p/span/strong[@class=\"price_real\"]/text()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mo_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"itemcase_basic\"]/p/span/span[@class=\"price_original\"]/text()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'links' is not defined"
     ]
    }
   ],
   "source": [
    "req = requests.get(links[1])\n",
    "resp = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "title = resp.xpath('//*[@id=\"itemcase_basic\"]/h1/text()')[0].extract()\n",
    "s_price = resp.xpath('//*[@id=\"itemcase_basic\"]/p/span/strong[@class=\"price_real\"]/text()')[0].extract()\n",
    "o_price = resp.xpath('//*[@id=\"itemcase_basic\"]/p/span/span[@class=\"price_original\"]/text()')[0].extract()\n",
    "discount_rate = str(round((1 - int(s_price.replace(',', '')) / int(o_price.replace(',', ''))) * 100, 2)) + '%'\n",
    "title, s_price, o_price, discount_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Define here the models for your scraped items\n",
      "#\n",
      "# See documentation in:\n",
      "# https://docs.scrapy.org/en/latest/topics/items.html\n",
      "\n",
      "import scrapy\n",
      "\n",
      "\n",
      "class CrawlerItem(scrapy.Item):\n",
      "    # define the fields for your item here like:\n",
      "    # name = scrapy.Field()\n",
      "    pass\n"
     ]
    }
   ],
   "source": [
    "!cat crawler/crawler/items.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting crawler/crawler/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class CrawlerItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    s_price = scrapy.Field()\n",
    "    o_price = scrapy.Field()\n",
    "    discount_rate = scrapy.Field()\n",
    "    link = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. spider.py 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting crawler/crawler/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/spiders/spider.py\n",
    "import scrapy\n",
    "from crawler.items import CrawlerItem\n",
    "\n",
    "class Spider(scrapy.Spider):\n",
    "    \n",
    "    # 어떻게 접속하겠다.\n",
    "    name = 'GmarketBestsellers'\n",
    "    allow_domain = ['gmarket.co.kr'] # 이 URL로 구성된 도메인만 크롤링 하겠다.\n",
    "    start_urls = ['http://corners.gmarket.co.kr/Bestsellers']\n",
    "    \n",
    "    # 받아서 어떻게 처리하겠다.\n",
    "    def parse(self, resp):\n",
    "        links = resp.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li/div/a/@href').extract()\n",
    "        for link in links[:50]:\n",
    "            yield scrapy.Request(link, callback=self.page_content)\n",
    "    def page_content(self, resp):\n",
    "        item = CrawlerItem()\n",
    "        item['title'] = resp.xpath('//*[@id=\"itemcase_basic\"]/h1/text()')[0].extract()\n",
    "        item['s_price'] = resp.xpath('//*[@id=\"itemcase_basic\"]/p/span/strong[@class=\"price_real\"]/text()')[0].extract()\n",
    "        try:\n",
    "            item['o_price'] = resp.xpath('//*[@id=\"itemcase_basic\"]/p/span/span[@class=\"price_original\"]/text()')[0].extract()\n",
    "        except:\n",
    "            item['o_price'] = item['s_price']\n",
    "        item['discount_rate'] = str(round((1 - int(item['s_price'].replace(',', '')) \n",
    "                                           / int(item['o_price'].replace(',', ''))) * 100, 2)) + '%'\n",
    "        item['link'] = resp.url\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. scrapy 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>link</th>\n",
       "      <th>o_price</th>\n",
       "      <th>s_price</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.67%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=15033...</td>\n",
       "      <td>30,000</td>\n",
       "      <td>19,900</td>\n",
       "      <td>[오뚜기밥] 맛있는 오뚜기밥 210g 24개</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=19345...</td>\n",
       "      <td>199,330</td>\n",
       "      <td>119,600</td>\n",
       "      <td>[빈폴스포츠] 롱패딩/경량다운 外 시즌맞춤 인기아우터 이너 모음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.15%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=15773...</td>\n",
       "      <td>95,000</td>\n",
       "      <td>88,210</td>\n",
       "      <td>[CASEY KIM] 이퓨쳐 Smart Phonics 1~5권(전5권) / 워크북 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.96%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=18240...</td>\n",
       "      <td>21,900</td>\n",
       "      <td>14,900</td>\n",
       "      <td>당일바리 생물 갑오징어 1kg(7~9미) 태안 산지직송</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.86%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=19353...</td>\n",
       "      <td>29,900</td>\n",
       "      <td>12,900</td>\n",
       "      <td>[에잇세컨즈] 에잇세컨즈 니트/가디건/티셔츠/후드/스커트+20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>45.23%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=16899...</td>\n",
       "      <td>19,900</td>\n",
       "      <td>10,900</td>\n",
       "      <td>우리네농산물 달콤한 왕만쥬빵 60gx30개입</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=11714...</td>\n",
       "      <td>32,900</td>\n",
       "      <td>32,900</td>\n",
       "      <td>[크리넥스] 데코 앤 소프트 화장지 27M30롤X2팩/휴지 +증정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>50.0%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=17260...</td>\n",
       "      <td>31,000</td>\n",
       "      <td>15,500</td>\n",
       "      <td>[슈퍼대디] 슈퍼대디x미피 제로 물티슈 캡형 80매10팩(55g)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>50.0%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=19176...</td>\n",
       "      <td>27,800</td>\n",
       "      <td>13,900</td>\n",
       "      <td>[스파클] 스파클생수 2L 30병(무료배송) 쿠폰가11820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>50.0%</td>\n",
       "      <td>http://item.gmarket.co.kr/Item?goodscode=19249...</td>\n",
       "      <td>19,800</td>\n",
       "      <td>9,900</td>\n",
       "      <td>천하일품 제주감귤 10kg 소과로얄(2S-S/M)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    discount_rate                                               link  o_price  \\\n",
       "0          33.67%  http://item.gmarket.co.kr/Item?goodscode=15033...   30,000   \n",
       "1           40.0%  http://item.gmarket.co.kr/Item?goodscode=19345...  199,330   \n",
       "2           7.15%  http://item.gmarket.co.kr/Item?goodscode=15773...   95,000   \n",
       "3          31.96%  http://item.gmarket.co.kr/Item?goodscode=18240...   21,900   \n",
       "4          56.86%  http://item.gmarket.co.kr/Item?goodscode=19353...   29,900   \n",
       "..            ...                                                ...      ...   \n",
       "195        45.23%  http://item.gmarket.co.kr/Item?goodscode=16899...   19,900   \n",
       "196          0.0%  http://item.gmarket.co.kr/Item?goodscode=11714...   32,900   \n",
       "197         50.0%  http://item.gmarket.co.kr/Item?goodscode=17260...   31,000   \n",
       "198         50.0%  http://item.gmarket.co.kr/Item?goodscode=19176...   27,800   \n",
       "199         50.0%  http://item.gmarket.co.kr/Item?goodscode=19249...   19,800   \n",
       "\n",
       "     s_price                                              title  \n",
       "0     19,900                          [오뚜기밥] 맛있는 오뚜기밥 210g 24개   \n",
       "1    119,600               [빈폴스포츠] 롱패딩/경량다운 外 시즌맞춤 인기아우터 이너 모음   \n",
       "2     88,210  [CASEY KIM] 이퓨쳐 Smart Phonics 1~5권(전5권) / 워크북 ...  \n",
       "3     14,900                    당일바리 생물 갑오징어 1kg(7~9미) 태안 산지직송   \n",
       "4     12,900               [에잇세컨즈] 에잇세컨즈 니트/가디건/티셔츠/후드/스커트+20%   \n",
       "..       ...                                                ...  \n",
       "195   10,900                          우리네농산물 달콤한 왕만쥬빵 60gx30개입   \n",
       "196   32,900              [크리넥스] 데코 앤 소프트 화장지 27M30롤X2팩/휴지 +증정   \n",
       "197   15,500              [슈퍼대디] 슈퍼대디x미피 제로 물티슈 캡형 80매10팩(55g)   \n",
       "198   13,900                 [스파클] 스파클생수 2L 30병(무료배송) 쿠폰가11820   \n",
       "199    9,900                       천하일품 제주감귤 10kg 소과로얄(2S-S/M)   \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('crawler/items.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. pipelines 설정\n",
    "- item을 출력하기 전에 실행되는 코드를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def send_slack(msg):\n",
    "    WEBHOOK_URL = 'https://hooks.slack.com/services/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'\n",
    "    payload = {\n",
    "        'channel': '#project',\n",
    "        'username': 'GIGI',\n",
    "        'text': msg,\n",
    "    }\n",
    "    requests.post(WEBHOOK_URL, json.dumps(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_slack('ㅗ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting crawler/crawler/pipelines.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/pipelines.py\n",
    "# %load crawler/crawler/pipelines.py\n",
    "# Define your item pipelines here\n",
    "#\n",
    "# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n",
    "# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "\n",
    "\n",
    "# useful for handling different item types with a single interface\n",
    "from itemadapter import ItemAdapter\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class CrawlerPipeline:\n",
    "    def __send_slack(self, msg):\n",
    "        WEBHOOK_URL = 'https://hooks.slack.com/services/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'\n",
    "        payload = {\n",
    "            'channel': '#project',\n",
    "            'username': 'GIGI',\n",
    "            'text': msg,\n",
    "        }\n",
    "        requests.post(WEBHOOK_URL, json.dumps(payload))\n",
    "        \n",
    "    def process_item(self, item, spider):\n",
    "        keyword = '마스크'\n",
    "        if keyword in item['title']:            \n",
    "            print('='*100)\n",
    "            print(item['title'])\n",
    "            print('='*100)\n",
    "            self.__send_slack('{}, {}, {}'.format(item['title'], item['s_price'], item['link']))\n",
    "            \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pipeline 설정 : settings.py\n",
    "\n",
    "```\n",
    "ITEM_PIPELINES = {\n",
    "    'crawler.pipelines.CrawlerPipeline': 300,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting crawler/crawler/settings.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/settings.py\n",
    "# %load crawler/crawler/settings.py\n",
    "# Scrapy settings for crawler project\n",
    "#\n",
    "# For simplicity, this file contains only settings considered important or\n",
    "# commonly used. You can find more settings consulting the documentation:\n",
    "#\n",
    "#     https://docs.scrapy.org/en/latest/topics/settings.html\n",
    "#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n",
    "#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n",
    "\n",
    "\n",
    "BOT_NAME = 'crawler'\n",
    "\n",
    "SPIDER_MODULES = ['crawler.spiders']\n",
    "NEWSPIDER_MODULE = 'crawler.spiders'\n",
    "\n",
    "\n",
    "# Crawl responsibly by identifying yourself (and your website) on the user-agent\n",
    "#USER_AGENT = 'crawler (+http://www.yourdomain.com)'\n",
    "\n",
    "# Obey robots.txt rules\n",
    "ROBOTSTXT_OBEY = False\n",
    "\n",
    "# Configure maximum concurrent requests performed by Scrapy (default: 16)\n",
    "#CONCURRENT_REQUESTS = 32\n",
    "\n",
    "# Configure a delay for requests for the same website (default: 0)\n",
    "# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n",
    "# See also autothrottle settings and docs\n",
    "#DOWNLOAD_DELAY = 3\n",
    "# The download delay setting will honor only one of:\n",
    "#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n",
    "#CONCURRENT_REQUESTS_PER_IP = 16\n",
    "\n",
    "# Disable cookies (enabled by default)\n",
    "#COOKIES_ENABLED = False\n",
    "\n",
    "# Disable Telnet Console (enabled by default)\n",
    "#TELNETCONSOLE_ENABLED = False\n",
    "\n",
    "# Override the default request headers:\n",
    "#DEFAULT_REQUEST_HEADERS = {\n",
    "#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "#   'Accept-Language': 'en',\n",
    "#}\n",
    "\n",
    "# Enable or disable spider middlewares\n",
    "# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n",
    "#SPIDER_MIDDLEWARES = {\n",
    "#    'crawler.middlewares.CrawlerSpiderMiddleware': 543,\n",
    "#}\n",
    "\n",
    "# Enable or disable downloader middlewares\n",
    "# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n",
    "#DOWNLOADER_MIDDLEWARES = {\n",
    "#    'crawler.middlewares.CrawlerDownloaderMiddleware': 543,\n",
    "#}\n",
    "\n",
    "# Enable or disable extensions\n",
    "# See https://docs.scrapy.org/en/latest/topics/extensions.html\n",
    "#EXTENSIONS = {\n",
    "#    'scrapy.extensions.telnet.TelnetConsole': None,\n",
    "#}\n",
    "\n",
    "# Configure item pipelines\n",
    "# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "#ITEM_PIPELINES = {\n",
    "#    'crawler.pipelines.CrawlerPipeline': 300,\n",
    "#}\n",
    "\n",
    "# Enable and configure the AutoThrottle extension (disabled by default)\n",
    "# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\n",
    "#AUTOTHROTTLE_ENABLED = True\n",
    "# The initial download delay\n",
    "#AUTOTHROTTLE_START_DELAY = 5\n",
    "# The maximum download delay to be set in case of high latencies\n",
    "#AUTOTHROTTLE_MAX_DELAY = 60\n",
    "# The average number of requests Scrapy should be sending in parallel to\n",
    "# each remote server\n",
    "#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n",
    "# Enable showing throttling stats for every response received:\n",
    "#AUTOTHROTTLE_DEBUG = False\n",
    "\n",
    "# Enable and configure HTTP caching (disabled by default)\n",
    "# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n",
    "#HTTPCACHE_ENABLED = True\n",
    "#HTTPCACHE_EXPIRATION_SECS = 0\n",
    "#HTTPCACHE_DIR = 'httpcache'\n",
    "#HTTPCACHE_IGNORE_HTTP_CODES = []\n",
    "#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n",
    "\n",
    "ITEM_PIPELINES = {\n",
    "    'crawler.pipelines.CrawlerPipeline': 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
